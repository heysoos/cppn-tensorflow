import numpy as np
import os
from PIL import Image
import matplotlib.pyplot as plt
from matplotlib import colors

def correlation_distance(imgs_list, dmin, dmax, N):
    # Calculate correlation function (correlation as a function of distance).

    # Summary: for each distance bin, find N pairs of points in the image with that distance. Calculate correlation
    # coefficient for the vectors generated by these pairs. Loop through all distance bins to get correlations as a
    # function of distance.

    # --- PARAMETERS ---
    # imgs_dir: directory of images
    # dmin, dmax: minimum and maximum distances
    # N: number of point pairs samples
    # ------------------

    corr_d = []
    for img_dir in imgs_list:
        img = np.array(Image.open(img_dir).convert('L')).flatten()
        res = np.sqrt(img.shape[0])  # img should be square...
        corr_d_img = []

        for d in np.arange(dmin, dmax):

            p, q = find_N_pairs(d, N, res)
            corr = np.corrcoef(img[p], img[q])[0, 1]

            corr_d_img.append(corr)

        corr_d.append(corr_d_img)

    return corr_d

def load_image_directories(filters, img_folder=None):

    # if len(filters) < 4:
    #     raise Exception('Please include more parameters in filter.')

    # transform filter dict to match savefile convention
    filters_isNone = {}
    sort_keys = []
    for k, v in filters.items():
        if filters[k] is None:
            filters_isNone[k] = ''
            sort_keys.append(k)
        else:
            filters_isNone[k] = str(filters[k]) + '_'
    sort_keys.append('iteration')

    filter_list = [
        'N' + str(filters_isNone['total_neurons']),
        'L' + str(filters_isNone['num_layers']),
        'w' + str(filters_isNone['omega']),
        'a' + str(filters_isNone['alpha']),
        'm' + str(filters_isNone['mu'])
    ]

    dir = 'save/img_architectures'
    img_dir = os.path.join(dir, img_folder)
    img_json_dir = os.path.join(img_dir, 'json')
    files = os.listdir(img_dir)

    # filter through imgs and keep only desired params

    img_list = []
    for file in files:
        if all(filter in file for filter in filter_list):
            img_list.append(file)

    # img_list.sort()

    # load files
    imgs = []
    imgs_params = []
    for img_ind in img_list:
        # create full pathname for individual img and its json file
        img_img_dir = os.path.join(img_dir, img_ind)
        img_img_json_dir = os.path.join(img_json_dir, os.path.splitext(img_ind)[0] + '.json')

        # load img directory
        imgs.append( img_img_dir )

    return imgs


def find_N_pairs(d, N, res):
    x1 = np.random.randint(0, res, N)
    y1 = np.random.randint(0, res, N)

    p = x1 * res + y1

    x2, y2 = random_walk(x1, y1, d, res)

    q = x2 * res + y2

    return p.astype('int'), q.astype('int')

def random_walk(x1, y1, d, res):

    alpha = 2 * np.pi * np.random.random(len(x1))

    dx = np.round(d * np.sin(alpha))
    dy = np.round(d * np.cos(alpha))

    x2 = x1 + dx
    y2 = y1 + dy

    # find all values that are out of bounds (oob)
    oob = (x2 > res - 1) + (x2 < 0) + (y2 > res - 1) + (y2 < 0)

    # TODO: there has to be a better way to do this, no? This seems way too slow...
    while any(oob):
        alpha = 2 * np.pi * np.random.random(np.sum(oob))

        dx = np.round(d * np.sin(alpha))
        dy = np.round(d * np.cos(alpha))

        x2[oob] = x1[oob] + dx
        y2[oob] = y1[oob] + dy

        oob = (x2 > res - 1) + (x2 < 0) + (y2 > res - 1) + (y2 < 0)

    return x2, y2

if __name__ == '__main__':

    ## FILTERS ##

    # set filters to None to load all images
    N = 500  # total_neurons
    L = 3  # num layers
    omega = 2  # omega
    alpha = 2  # alpha
    mu = 1  # mu


    alpha_plot = 1
    s = 2

    Ns = [100, 250, 500]
    # Ls = [3, 5, 10]
    # mus = [0, 0.1, -0.1, 0.5, -0.5, 1, -1]

    cmap = plt.get_cmap('tab10')
    norm = colors.Normalize(vmin=0, vmax=len(Ns))  # age/color mapping

    for ii, N in enumerate(Ns):
        filters = {
            'total_neurons': N,
            'num_layers': L,
            'omega': omega,
            'alpha': alpha,
            'mu': mu,
        }

        img_folder = '19-05-06-20-15-32.049534'

        imgs_list = load_image_directories(filters, img_folder)

        dmin = 1
        dmax = 300
        N_samples = 10000

        corr_d = correlation_distance(imgs_list, dmin, dmax, N_samples)
        c = cmap(norm(ii))
        d = np.arange(dmin, dmax)

        plt.plot(d, np.mean(corr_d, axis=0), color=c, label=str(N))

        # for corr in corr_d:
        #     plt.scatter(d, corr, color=c, alpha=alpha_plot, s=s, label=str(mu))
    # plt.yscale('log')
    # plt.xscale('linear')
    plt.legend()
    plt.show()
