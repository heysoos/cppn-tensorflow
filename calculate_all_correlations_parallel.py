import numpy as np
import os
import pickle
import matplotlib.pyplot as plt
from PIL import Image
import scipy.signal
# import pathos.multiprocessing as mp
# import tqdm
# import pathos
from p_tqdm import p_map, p_imap

def correlation_distance(img_path, dmin, dmax, N):
    # Calculate correlation function (correlation as a function of distance).

    # Summary: for each distance bin, find N pairs of points in the image with that distance. Calculate correlation
    # coefficient for the vectors generated by these pairs. Loop through all distance bins to get correlations as a
    # function of distance.

    # --- PARAMETERS ---
    # imgs_dir: directory of images
    # dmin, dmax: minimum and maximum distances
    # N: number of point pairs samples
    # ------------------

    img = np.array(Image.open(img_path).convert('L')).flatten()  # load img > convert to greyscale > flatten
    res = np.sqrt(img.shape[0])  # img should be square...

    # calculate correlation for each distance bin
    corr_d_img = []
    for d in np.arange(dmin, dmax):

        p, q = find_N_pairs(d, N, int(res))
        corr = np.corrcoef(img[p], img[q])[0, 1]

        corr_d_img.append(corr)

    return corr_d_img

def fft_autocorr(img_path, method='fft'):


    img = np.array(Image.open(img_path).convert('L')) / 255

    img_mean = np.mean(np.mean(img))  # calculate mean
    img = img - img_mean  # subtract mean

    if method == 'fft_windowed':
        # apply hanning window function
        h = np.outer( np.hanning(len(img)), np.hanning(len(img)) )
        img = img * h

    img_squared_mean = np.mean(np.mean(img**2))

    nm = np.product(np.shape(img))

    corr = scipy.signal.fftconvolve(img, img[::-1, ::-1]) / nm / img_squared_mean


    shape = np.shape(corr)
    iu = np.triu_indices(n=shape[0], m=shape[1])

    return corr[iu]


def load_image_directories(img_folder=None):
    # make a list of all imgs in image directory

    dir = 'save/img_architectures'
    imgs_folder = os.path.join(dir, img_folder)
    imgs_paths = [os.path.join(imgs_folder, f) for f in os.listdir(imgs_folder) if f.endswith('.png')]

    return imgs_paths


def find_N_pairs(d, N, res):
    # find N pairs of coordinates that are distance d apart
    x1 = np.random.randint(0, res, N)
    y1 = np.random.randint(0, res, N)

    p = x1 * res + y1

    x2, y2 = random_walk(x1, y1, d, res)

    q = x2 * res + y2

    return p.astype('int'), q.astype('int')

def random_walk(x1, y1, d, res):
    # use random walk to find a second coordinate (x2, y2) from starting point (x1, y1)
    alpha = 2 * np.pi * np.random.random(len(x1))

    dx = np.round(d * np.sin(alpha))
    dy = np.round(d * np.cos(alpha))

    x2 = x1 + dx
    y2 = y1 + dy

    # find all values that are out of bounds (oob)
    oob = (x2 > res - 1) + (x2 < 0) + (y2 > res - 1) + (y2 < 0)

    # TODO: there has to be a better way to do this, no? This seems dangerous using a while loop...
    while any(oob):
        alpha = 2 * np.pi * np.random.random(np.sum(oob))

        dx = np.round(d * np.sin(alpha))
        dy = np.round(d * np.cos(alpha))

        x2[oob] = x1[oob] + dx
        y2[oob] = y1[oob] + dy

        oob = (x2 > res - 1) + (x2 < 0) + (y2 > res - 1) + (y2 < 0)

    return x2, y2

def generate_params(method, img_folder, corr_folder, dmin=None, dmax=None, N=None):

    img_paths = load_image_directories(img_folder)

    params = [ (method, img_path, corr_folder, dmin, dmax, N) for img_path in img_paths ]

    return params


def show_image(img_dir):
    img = Image.open(img_dir)
    plt.imshow(img)
    plt.show()

def dist_vec(shape):
    n = shape[0]
    m = shape[1]
    iu = np.triu_indices(n=n, m=m, k=0)

    distu = np.sqrt((iu[0] - (n-1)/2)**2 + (iu[1] - (m-1)/2)**2)

    return distu


def calc_and_save_corrs(method, img_path, corr_folder, dmin=None, dmax=None, N=None):

    if method == 'sample':
        corr = correlation_distance(img_path, dmin, dmax, N)
    elif method == 'fft' or method == 'fft_windowed':
        corr =  fft_autocorr(img_path, method)
    # elif method == 'full':
        # corr = ...
        #  TODO: full sampling

    else:
        raise Exception('Method must be either \'fft\' or \'sample\'.')

    new_base = os.path.splitext(os.path.basename(img_path))[0] + '.txt'
    savename = os.path.join(corr_folder, new_base)

    with open(savename, 'wb') as fp:
        pickle.dump(corr, fp)

    # status_txt = 'Saving correlation: ' + new_base
    # print(status_txt)


if __name__ == '__main__':

    method = 'fft_windowed'  # 'sample', 'fft', 'fft_windowed',  'full'

    if method == 'sample':
        dmin = 1  # minimum distance
        dmax = 300  # maximum distance (be careful making this too large, can get stuck in while loops!)
        N = int(1e5)  # 10 000 samples per distance

    # img_folder = '19-05-06-20-15-32.049534'
    img_folder = 'big'
    corr_folder = os.path.join('save/img_architectures/', img_folder, 'corrs', method)

    if not os.path.exists(corr_folder):
        os.makedirs(corr_folder)

    # params = generate_params(method, img_folder, corr_folder, dmin, dmax, N)
    params = generate_params(method, img_folder, corr_folder)

    ## MULTIPROCESSING EXPERIMENTS ##

    # pool = Pool(processes=11)
    # pool.starmap(calc_and_save_corrs, params)


    ## PATHOS EXPERIMENTS##

    # f = lambda x: calc_and_save_corrs(*x)
    # pool = mp.ProcessingPool()
    # # pool.map(f, params)
    # list(tqdm.tqdm(pool.imap(f, params), total=len(params)))



    ## P_TQDM EXPERIMENTS ##
    num_cpus = 11
    f = lambda x: calc_and_save_corrs(*x)
    list(p_imap(f, params, num_cpus=num_cpus))

